---
title: "FIS project : main notebook"
output: html_notebook
---
### 1) Cargamos los datos

Para empezar, cargamos el train set y el test set.
```{r}
df_train <-read.csv2("data/train.csv")
df_test <- read.csv2("data/test.csv")
```

Verificamos las dimensiones del dataset de entrenamiento y del dataset de test.
```{r}
dim_train = dim(df_train)
print(paste("El cunjunto de entrenamiento tiene ", dim_train[1],"valores y ", dim_train[2], "variables." ))

dim_test = dim(df_test)
print(paste("El cunjunto de test tiene ", dim_test[1],"valores y ", dim_test[2], "variables." ))

```

Visualizamos el header del dataset de entrenamiento para ver un poco los datos.
```{r}
head(df_train)
```


### 2) Exploración y visualización de los datos

Para conocer un poco más los datos vamos a visuzalizar cada variable del dataset de entrenamiento.
```{r}
# Cargamos la librería tidyverse para manipular los datos más facilmente

library(tidyverse)

# Gracias a eso, ahora podemos utilizar el operador %>% para crear una pipeline en la que aplicamos varias operaciones a los datos (por ejemplo "mutate" para añadir nuevas variables, "select" para guardar solamente las variables que queremos, "filter" para filtrar los datos según valores, etc).

```

#### Visualización de la variable "age"

Esta variable representa la edad de cada cliente. Es una variable numérica y vamos a visualizarla con un gráfico que representa en el eje "x" la edad y en el eje "y" el número de clientes que tienen esa edad. Sin embargo, como hay muchos edades diferentes vamos a crear grupos de edad para que sea más facil visualizar.

```{r}

# creamos grupos de edad porque hay muchos edades diferentes
# creamos una variable que cuenta para cada grupo de edad el número de clientes

edad <- df_train %>%
  mutate(edad_interval = cut_interval(df_train$age, length = 5)) %>%
  group_by(edad_interval) %>%
  count()

# visualizamos eso en un gráfico

 ggplot(edad, aes(x = edad_interval, y=n)) +
   geom_bar(stat="identity") +
   ggtitle("Número de clientes en función de la edad") +
   labs(x="edad", y = "número de clientes")
```
Podemos ver que la mayoria de los clientes tienen entre 25 y 60 años y muchos tienen entre 30 y 40 años. Los clientes representan bien la mayoria de la población trabajadora.

#### Visualización de la variable "job"

Esta variable representa qué tipo de trabajo tiene cada cliente. Es una variable categórica (es decir que la variable sólo puede tomar un número finito de categorías) y nominal (es decir que no hay orden entre las diferentes categorías). Vamos a visualizarla con un gráfico circular.

```{r}

# creamos una variable que cuenta para cada job el número de clientes, y clasificamos los jobs del que tiene más clientes al que tiene menos

job <- df_train %>%
  group_by(df_train$job) %>%
  count() %>%
  arrange(desc(n))

# vamos a utilizar la paleta de colores "viridis" para la visualización (hace falta descomentar la siguiente línea si ya no está instalado)
# install.packages("viridis")
library("viridis")

# construimos el gráfico
pie(x=job$n,
    labels = job$`df_train$job`,
    radius = 1,
    main = "Número de clientes en función del job",
    col = viridis(length(job$n)))
```
Ahora podemos ver los jobs mayoritarios entre los clientes. Observamos que los clientes tienen muchos tipos de jobs, así que los datos son representativos de la población (no representan una única categoría profesional).

#### Visualización de la variable "marital"

Esta variable representa la situación marital de cada cliente. Vamos a visuarla de la misma manera que la variable anterior porque es una variable categórica y nominal.

```{r}

# creamos un variable que cuenta para cada estado posible de la variable "marital" el número de clientes que están en este estado
# clasificamos los estados del que tiene  más clientes al que tiene menos

marital <- df_train %>%
  group_by(df_train$marital) %>%
  count() %>%
  arrange(desc(n))

# visualizamos eso en un gráfico circular (de la misma manera que para la variable "jobs")

pie(x=marital$n,
    labels = marital$`df_train$marital`,
    radius = 1,
    main = "Clientes en función del valor de la variable marital",
    col = viridis(length(marital$n)))

```

De nuevo podemos observar que los datos representan bien cada categoría de la población porque hay muchos cientes para cada categoría.

#### Visualización de la variable "education"

Esta variable representa el nivel de educación de cada cliente. Es una variable categórica y nominal.

```{r}

nivel_educación <- df_train %>%
  group_by(df_train$education) %>%
  count() %>%
  arrange(desc(n))

pie(x=nivel_educación$n,
    labels = nivel_educación$`df_train$education`,
    radius = 1,
    main = "Nivel de educación de los clientes",
    col = viridis(length(nivel_educación$n)))


```
Otra vez podemos ver que los datos representan bien cada categoría de la población.

#### Visualización de la variable "default"

Esta variable trata de si los clientes tienen un credito impagado (si o no). Es una variable binaria que también vamos a visualizar con un gráfico circular.

```{r}

crédito_impagado <- df_train %>%
  group_by(df_train$default) %>%
  count()

pie(x=crédito_impagado$n,
    labels = crédito_impagado$`df_train$default`,
    radius = 1,
    main = "Clientes que tienen un crédito impagado y los que no",
    col = viridis(length(crédito_impagado$n)))

```
Podemos ver que la mayoría de los clientes no tienen crédito impagado.

#### Visualización de la variable "balance"

Esta variable representa el saldo anual medio (en euros) de los clientes.

```{r}
 
 ggplot(df_train, aes(x = balance)) +
  geom_histogram(bins = 30) +
  ggtitle("Número de clientes en función del saldo anual medio") +
  labs(x="saldo anual medio (euros)", y = "número de clientes") +
  xlim(-5000, 25000)
```
Podemos ver que la mayoría de los clientes tienen un saldo anual medio cerca de 0 (menos de 5000 euros), mientras que hay una pequeña parte de los clientes que tienen un saldo anual medio más importante. Esto parece ser representativo de la población.

#### Visualización de la variable "housing"

Esta variable determina si el cliente tiene una propiedad (si o no).

```{r}
housing <- df_train %>%
  group_by(df_train$housing) %>%
  count()

pie(x=housing$n,
    labels = housing$`df_train$housing`,
    radius = 1,
    main = "Repartición de los clientes en función de si tienen una propiedad o no",

    col = viridis(length(housing$n)))
```
Podemos ver que tenemos muchos clientes para ambas categorías.

#### Visualización de la variable "loan"

Esta variable determina si el cliente tiene prestamos activos (si o no).

```{r}
loan <- df_train %>%
  group_by(df_train$loan) %>%
  count()

pie(x=loan$n,
    labels = loan$`df_train$loan`,
    radius = 1,
    main = "Repartición de los clientes en función de si tienen un credito activo o no",
    col = viridis(length(loan$n)))
```
Muchos clientes no tienen credito activo pero ambas categorías están bien representadas, así que esta variable también parece ser representativo de la población.

#### Visualización de la variable "contact"

Esta variable determina el medio por el cual el cliente fue contactado.

```{r}

contact <- df_train %>%
  group_by(df_train$contact) %>%
  count()

pie(x=contact$n,
    labels = contact$`df_train$contact`,
    radius = 1,
    main = "Número de clientes en función del medio por el cuál fueron contactados",
    col = viridis(length(contact$n)))
```
No hay mucho que interpretar de este gráfico.

#### Visualización de la variable "day"

Esta variable representa el día del mes en el cual fue contactado el cliente. Puede ser útil tener eso porque puede tener un impacto en la decisión del cliente. Por ejemplo los clientes pueden decir mas facilmente "si" al principio del mes.

```{r}

ggplot(df_train, aes(x = df_train$day)) +
  geom_histogram(bins = 31) +
  ggtitle("Número de clientes en función del día en el cual fueron contactados") +
  labs(x="día del mes", y = "número de clientes")

```

En general, podemos observar que hay muchos clientes para cada día del mes, así que no hay desequilibrio en los datos.

#### Visualización de la variable "duration"

Esta variable representa la duración de la llamdada (en segundos).

```{r}

ggplot(df_train, aes(x = df_train$duration)) +
  geom_histogram(bins = 20) +
  ggtitle("Número de clientes en función de la duración de la llamada") +
  labs(x="duración de la llamdada (segundos)", y = "número de clientes") +
  xlim(0,1000)

```

Sólo podemos observar que la mayoría de las llamadas duran menos de 10 minutos y muchas duran 2-3 minutos.

Las visualización de las siguientes variables es de poco interés, así que ahora solo vamos a visualizar la clase final.

#### Visualización de la clase final

Esta variable dice si el cliente ha suscrito a un un term deposit (si o no). La visualización de esta variable permite ver si no hay desequilibrio entre las 2 clases que queremos predecir.

```{r}

clase_final <- df_train %>%
  group_by(df_train$y) %>%
  count()

pie(x=clase_final$n,
    labels = clase_final$`df_train$y`,
    radius = 1,
    main = "Número de clientes en función de si han suscrito a un un term deposit",
    col = viridis(length(clase_final$n)))

```
Podemos observar que hay un pequeño desequilibrio entre las clases pero no demasiado importante.

Para concluir sobre esta parte de visualización, podemos decir que tenemos muchos datos (más de 47 000), y además son datos muy completos que representan muchos tipos de clientes diferentes. Por lo tanto, es un buen conjunto de datos para entrenar modelos predictivos.

### Regresión

Ahora aplicamos regresión para predecir el saldo del cliente.



```{r}
model <- lm(balance ~ ., data = df_train[,-c(12)])
summary(model)
```

```{r}
par(mfrow=c(2,2))
plot(model)
```

El valor de R_squared es 0.04, lo que significa solo el 4% de la variación en la variable de respuesta explicada por las variables de entrada, lo que significa que el modelo no se ajusta bien a los datos.



### 3) Entrenamiento de clasificadores
Ahora, vamos a entrenar varios clasificadores para predecir si el cliente es interesante o no. Vamos a probar cada clasificador con el conjunto de test y despues vamos a comparar los resultados de cada uno para elegir lo mejor.

#### Árbol de decisión con Rpart

```{r}
#aplicando árbol de decisión con rpart en datos de entrenamiento
library(rpart)

mytree <- rpart(
  y ~ ., 
  data = df_train, 
  method = "class"
)
mytree
```


```{r}
#Trazado del clasificador de árbol de decisión
#install.packages(rpart.plot)
library(rpart.plot)
rpart.plot(mytree)
```



```{r}
#hacer predicciones sobre datos de prueba
preds <- predict(mytree, newdata = df_test, type = "class")
```

```{r}
#comprobar la precisión del árbol de decisiones en los datos de prueba
mean(preds == df_test$y)
```
```{r}
#Matriz de confusión del árbol de decisión sobre los datos de prueba.
table(df_test$y, preds)
```

De las métricas de evaluación de desempeño anteriores, observé que el árbol de decisiones con rpart tiene una precisión de 0.90 en los datos de prueba. El árbol de decisión predice 4073 observaciones correctamente de las 4521 observaciones en los datos de prueba.

#### Clasificador Knn

```{r}
#convertir variables categóricas en numéricas para los datos de entrenamiento
#install.packages("fastDummies")
library(fastDummies)
df_traind <- df_train
df_traind$default <- ifelse(df_traind$default == "yes",1,0)
df_traind$housing <- ifelse(df_traind$housing == "yes",1,0)
df_traind$loan <- ifelse(df_traind$loan == "yes",1,0)
df_traind$month <- recode(df_traind$month, "jan" = 1, "feb" = 2, "mar" = 3, "apr" = 4,  "may" = 5, "jun" = 6, "jul" = 7, "aug" = 8, "sep" = 9, "oct" = 10, "nov" = 11, "dec" = 12)
df_traind <- dummy_cols(df_traind,remove_selected_columns = T, select_columns = c("job", "marital", "education", "contact", "poutcome"))
```


```{r}
#convertir variables categóricas en numéricas para datos de prueba
df_testd <- df_test
df_testd$default <- ifelse(df_testd$default == "yes",1,0)
df_testd$housing <- ifelse(df_testd$housing == "yes",1,0)
df_testd$loan <- ifelse(df_testd$loan == "yes",1,0)

df_testd$month <- recode(df_testd$month, "jan" = 1, "feb" = 2, "mar" = 3, "apr" = 4,  "may" = 5, "jun" = 6, "jul" = 7, "aug" = 8, "sep" = 9, "oct" = 10, "nov" = 11, "dec" = 12)

df_testd <- dummy_cols(df_testd,remove_selected_columns = T, select_columns = c("job", "marital", "education", "contact", "poutcome"))
```


```{r}
#aplicando clasificación usando el modelo KNN
#install.packages("class")
library(class)
knn_classifier <- knn(train = df_traind[,-c(12)],
                      test = df_testd[, -c(12)],
                      cl = df_traind$y, k = 2)
```


```{r}
mean(df_testd$y == knn_classifier)
```

```{r}
table(df_testd$y, knn_classifier)
```

De las métricas de evaluación de desempeño anteriores, observé que Knn tiene una precisión de 0.927, el clasificador de Knn predice 4197 de 4521 observaciones correctamente. Dado que el rendimiento del clasificador knn es más alto que el del árbol de decisión con rpart, el clasificador knn se generaliza y se ajusta bien a los datos y funciona mejor que el árbol de decisión con rpart y se puede utilizar para predicciones futuras.

### 4) Aplicación de algoritmos de clustering

Para terminar, vamos a aplicar varios algoritmos de clustering para ver si el conjunto de clientes se puede dividir en varios subconjuntos con clientes que se aparecen, y comparar los resultados de estos algoritmos de clustering.
#### Kmeans Clustering

```{r}
#aplicando kmeans clustering con k = 2
set.seed(1)
df_test2 <- df_testd
km2 <- kmeans(df_test2[,-c(12)], centers = 2, nstart = 25)
km2
```
```{r}
df_test2$cluster = factor(km2$cluster)
df_test2$cluster
centers=as.data.frame(km2$centers)
centers
```

```{r}
#Preparar grupos de balance de duración para graficar
duration_balance= ggplot(data=df_test2, aes(x=duration, y=balance, color=cluster )) + 
  geom_point() +
  geom_point(data=centers, aes(x=age,y=balance, color=as.factor(c(1,2))), 
             size=10, alpha=.3, show.legend=FALSE)#guide=FALSE)
# Trazar trama de clústeres de duration_balance
duration_balance
```



```{r}
df_test2$cluster <- ifelse(df_test2$cluster == 1,"no", "yes")
table(df_test2$y, df_test2$cluster)
```


```{r}
#aplicando kmeans clustering con k = 3
set.seed(1)
df_test3 <- df_testd
km3 <- kmeans(df_test3[,-c(12)], centers = 3, nstart = 25)
km3
```


```{r}
df_test3$cluster = factor(km3$cluster)
df_test3$cluster
centers=as.data.frame(km3$centers)
centers
```


```{r}
#Preparar grupos de balance de duración para graficar
duration_balance= ggplot(data=df_test3, aes(x=duration, y=balance, color=cluster )) + 
  geom_point() +
  geom_point(data=centers, aes(x=age,y=balance, color=as.factor(c(1,2,3))), 
             size=10, alpha=.3, show.legend=FALSE)#guide=FALSE)
#Trazar trama de clústeres de duration_balance
duration_balance
```



```{r}
ggscatter(
  df_test3, x = "duration", y = "balance", 
  color = "cluster", palette = "npg", ellipse = TRUE, ellipse.type = "convex",
  size = 1.5,  legend = "right", ggtheme = theme_bw(),
  xlab = "Duration",
  ylab = "Balance"
) +
  stat_mean(aes(color = cluster), size = 4)
```




```{r}
#aplicando kmeans clustering con k = 3
set.seed(1)
df_test4 <- df_testd
km4 <- kmeans(df_test4[,-c(12)], centers = 4, nstart = 25)
km4
```


```{r}
df_test4$cluster = factor(km4$cluster)
df_test4$cluster
centers=as.data.frame(km4$centers)
centers
```


```{r}
#Preparar grupos de balance de duración para graficar
duration_balance= ggplot(data=df_test4, aes(x=duration, y=balance, color=cluster )) + 
  geom_point() +
  geom_point(data=centers, aes(x=age,y=balance, color=as.factor(c(1,2,3, 4))), 
             size=10, alpha=.3, show.legend=FALSE)#guide=FALSE)
#Trazar trama de clústeres de duration_balance
duration_balance
```



```{r}
ggscatter(
  df_test4, x = "duration", y = "balance", 
  color = "cluster", palette = "npg", ellipse = TRUE, ellipse.type = "convex",
  size = 1.5,  legend = "right", ggtheme = theme_bw(),
  xlab = "Duration",
  ylab = "Balance"
) +
  stat_mean(aes(color = cluster), size = 4)
```



A partir de las visualizaciones, observé que los datos se agrupan más claramente en dos grupos en comparación con tres o cuatro grupos.


#### Cluseting jerárquico

```{r, warning = F}
# realizar agrupaciones jerárquicas en datos de prueba
clusters <- hclust(dist(df_testd))
group = cutree(clusters, 2)

```


```{r}
#comprobar cuántos valores cumplen con el valor real de y
group <- ifelse(group == 1, "no", "yes")
table(df_testd$y, group)
```


```{r}
# Preparar grupos de balance de duración para graficar
water_protein= ggplot(data=df_testd, aes(x=duration, y=balance, color=group)) + 
  geom_point()
  
water_protein
```



```{r}
df_testd$cluster <- group
ggscatter(
  df_testd, x = "duration", y = "balance", 
  color = "cluster", palette = "npg", ellipse = TRUE, ellipse.type = "convex",
  size = 1.5,  legend = "right", ggtheme = theme_bw(),
  xlab = "Duration",
  ylab = "Balance"
) +
  stat_mean(aes(color = cluster), size = 4)
```

De la tabla anterior, observé que el agrupamiento jerárquico agrupa casi todos los puntos de datos en 1 grupo que es no. K significa que la agrupación en clústeres también agrupa los puntos de datos como sí, por lo que K significa que la agrupación en clústeres funciona mejor que la agrupación jerárquica.



